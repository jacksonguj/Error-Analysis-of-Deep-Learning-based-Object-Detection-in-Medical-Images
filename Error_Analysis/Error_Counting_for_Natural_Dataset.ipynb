{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayeonKangNature/Bachelor_Project_Thesis_2023/blob/main/Error_Counting_for_Natural_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For mouting\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import os\n",
        "import json\n",
        "\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "id": "5plvGry27Sok",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94be4b37-94ab-42db-adb8-f75f0beb2ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rK6SVXOb6U3J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6460b4ed-79c9-488e-9f82-19515dedf86d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  777M  100  777M    0     0  94.0M      0  0:00:08  0:00:08 --:--:-- 95.8M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  241M  100  241M    0     0  75.0M      0  0:00:03  0:00:03 --:--:-- 75.0M\n"
          ]
        }
      ],
      "source": [
        "# Download images and annotations\n",
        "!curl http://images.cocodataset.org/zips/val2017.zip --output coco_valid.zip\n",
        "!curl http://images.cocodataset.org/annotations/annotations_trainval2017.zip --output coco_valid_anns.zip\n",
        "# Unzip images into coco_val2017/images\n",
        "!mkdir coco_val2017/\n",
        "!unzip -q coco_valid.zip -d coco_val2017/\n",
        "!mv -f coco_val2017/val2017 coco_val2017/images\n",
        "# Unzip and keep only valid annotations as coco_val2017/annotations.json\n",
        "!unzip -q coco_valid_anns.zip -d coco_val2017\n",
        "!mv -f coco_val2017/annotations/instances_val2017.json coco_val2017/annotations.json\n",
        "!rm -rf coco_val2017/annotations\n",
        "# Remove zip files downloaded\n",
        "!rm -f coco_valid.zip\n",
        "!rm -f coco_valid_anns.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Tuple\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "DATA_PATH = Path(\"/content/coco_val2017\")\n",
        "images_path = Path(\"/content/coco_val2017/images\")\n",
        "\n",
        "def load_dataset(\n",
        "    data_path: Path = DATA_PATH,\n",
        ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"Read the COCO style json dataset and transform it into convenient DataFrames\n",
        "    :return (images_df, targets_df):\n",
        "        images_df: Columns \"image_id\" and \"file_name\"\n",
        "        targets_df: Columns\n",
        "            \"target_id\", \"image_id\", \"xmin\", \"ymin\", \"xmax\", \"ymax\", \"label_id\"\n",
        "    \"\"\"\n",
        "    annotations_path = data_path / \"annotations.json\"\n",
        "\n",
        "    with open(annotations_path, \"r\") as f:\n",
        "        targets_json = json.load(f)\n",
        "\n",
        "    images_df = pd.DataFrame.from_records(targets_json[\"images\"])\n",
        "    images_df.rename(columns={\"id\": \"image_id\"}, inplace=True)\n",
        "    images_df = images_df[[\"image_id\", \"file_name\"]]\n",
        "\n",
        "    targets_df = pd.DataFrame.from_records(targets_json[\"annotations\"])\n",
        "    targets_df[[\"xmin\", \"ymin\", \"w\", \"h\"]] = targets_df[\"bbox\"].tolist()\n",
        "    targets_df[\"xmax\"] = targets_df[\"xmin\"] + targets_df[\"w\"]\n",
        "    targets_df[\"ymax\"] = targets_df[\"ymin\"] + targets_df[\"h\"]\n",
        "    targets_df.reset_index(inplace=True)\n",
        "    targets_df.rename(\n",
        "        columns={\"index\": \"target_id\", \"category_id\": \"label_id\"}, inplace=True\n",
        "    )\n",
        "    targets_df = targets_df[\n",
        "        [\"target_id\", \"image_id\", \"label_id\", \"xmin\", \"ymin\", \"xmax\", \"ymax\"]\n",
        "    ]\n",
        "\n",
        "    return images_df, targets_df\n",
        "\n",
        "images_df, targets_df = load_dataset(DATA_PATH)"
      ],
      "metadata": {
        "id": "VSEUHriI6ftS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(images_path, targets_df)"
      ],
      "metadata": {
        "id": "3d8nSghC6hPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43f73f4a-631f-46d5-c78e-3cbb533f6c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/coco_val2017/images        target_id  image_id  label_id    xmin    ymin    xmax    ymax\n",
            "0              0    289343        18  473.07  395.93  511.72  424.60\n",
            "1              1     61471        18  272.10  200.23  424.07  480.00\n",
            "2              2    472375        18  124.71  196.18  497.56  552.99\n",
            "3              3    520301        18  112.71  154.82  480.00  634.17\n",
            "4              4    579321        18  200.61   89.65  600.83  340.67\n",
            "...          ...       ...       ...     ...     ...     ...     ...\n",
            "36776      36776     15517         6  197.00  248.00  461.00  293.00\n",
            "36777      36777    439994         1    0.00    0.00  427.00  458.00\n",
            "36778      36778    117719        44    6.00   75.00  480.00  338.00\n",
            "36779      36779     50149        52   10.00   41.00  413.00  193.00\n",
            "36780      36780    250282         1    0.00   34.00  639.00  422.00\n",
            "\n",
            "[36781 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/BSc_Project/Main_code_folder/TIMOTHY/preds_df_yolo_natural.csv\")\n",
        "preds_df = data"
      ],
      "metadata": {
        "id": "_yLA3sOm66QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(preds_df)"
      ],
      "metadata": {
        "id": "YkcNeodt6mlM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0cd45cc-93d3-4b7b-c953-d9e0777bd71c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Unnamed: 0  pred_id  image_id  label_id     xmin     ymin     xmax  \\\n",
            "0                0        0    298251        24   70.000   90.500  137.250   \n",
            "1                1        1    298251        24  520.500  105.250  562.500   \n",
            "2                2        2    298251        24  560.500   61.875  584.500   \n",
            "3                3        3    298251        24  378.000   64.625  396.500   \n",
            "4                4        4    298251        24  416.000  109.375  467.500   \n",
            "...            ...      ...       ...       ...      ...      ...      ...   \n",
            "579420      579420   579420     42102        32  120.750  114.250  142.250   \n",
            "579421      579421   579421     42102        27   10.750  374.500   69.000   \n",
            "579422      579422   579422     42102        31   11.688  439.750   68.813   \n",
            "579423      579423   579423     42102        33   10.750  374.500   69.000   \n",
            "579424      579424   579424     42102        32  121.375  116.125  137.875   \n",
            "\n",
            "           ymax    score  \n",
            "0       134.000  0.94678  \n",
            "1       145.000  0.92920  \n",
            "2       102.625  0.92041  \n",
            "3       100.625  0.90576  \n",
            "4       126.125  0.81689  \n",
            "...         ...      ...  \n",
            "579420  262.750  0.90332  \n",
            "579421  564.500  0.00534  \n",
            "579422  566.000  0.00280  \n",
            "579423  564.500  0.00219  \n",
            "579424  164.875  0.00168  \n",
            "\n",
            "[579425 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright Â© 2022 Bernat Puig Camps\n",
        "from typing import Dict, Set, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "TARGETS_DF_COLUMNS = [\n",
        "    \"target_id\",\n",
        "    \"image_id\",\n",
        "    \"label_id\",\n",
        "    \"xmin\",\n",
        "    \"ymin\",\n",
        "    \"xmax\",\n",
        "    \"ymax\",\n",
        "]\n",
        "PREDS_DF_COLUMNS = [\n",
        "    \"pred_id\",\n",
        "    \"image_id\",\n",
        "    \"label_id\",\n",
        "    \"xmin\",\n",
        "    \"ymin\",\n",
        "    \"xmax\",\n",
        "    \"ymax\",\n",
        "    \"score\",\n",
        "]\n",
        "ERRORS_DF_COLUMNS = [\"pred_id\", \"target_id\", \"error_type\"]\n",
        "\n",
        "BACKGROUND_IOU_THRESHOLD = 0.1\n",
        "FOREGROUND_IOU_THRESHOLD = 0.5\n",
        "\n",
        "\n",
        "class ErrorType:\n",
        "    OK = \"correct\"  # pred -> IoU > foreground; target_label == pred_label; highest score\n",
        "    CLS = \"classification\"  # pred -> IoU > foreground; target_label != pred_label\n",
        "    LOC = \"localization\"  # pred -> background < IoU < foreground; target_label == pred_label\n",
        "    CLS_LOC = \"cls & loc\"  # pred -> background < IoU < foreground; target_label != pred_label\n",
        "    DUP = \"duplicate\"  # pred -> background < IoU < foreground; target_label != pred_label\n",
        "    BKG = \"background\"  # pred -> IoU > foreground; target_label == pred_label; no highest score\n",
        "    MISS = \"missed\"  # target -> No pred with Iou > background\n",
        "\n",
        "\n",
        "def classify_predictions_errors(\n",
        "    targets_df: pd.DataFrame,\n",
        "    preds_df: pd.DataFrame,\n",
        "    iou_background: float = BACKGROUND_IOU_THRESHOLD,\n",
        "    iou_foreground: float = FOREGROUND_IOU_THRESHOLD,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Classify predictions\n",
        "    We assume model is right as much as possible. Thus, in case of doubt\n",
        "    (i.e matching two targets), a prediction will be first considered\n",
        "    ErrorType.LOC before ErrorType.CLS.\n",
        "    The error definition credit belongs to the following paper (refer to it for\n",
        "    conceptual details):\n",
        "        TIDE: A General Toolbox for Identifying Object Detection Errors\n",
        "        https://arxiv.org/abs/2008.08115\n",
        "    :param targets_df: DataFrame with all targets for all images with TARGETS_DF_COLUMNS.\n",
        "    :param preds_df: DataFrame with all predictions for all images with PREDS_DF_COLUMNS.\n",
        "    :param iou_background: Minimum IoU for a prediction not to be considered background.\n",
        "    :param iou_foreground: Minimum IoU for a prediction to be considered foreground.\n",
        "    :return errors_df: DataFrame with all error information with ERRORS_DF_COLUMNS\n",
        "    \"\"\"\n",
        "\n",
        "    # Provide clarity on expectations and avoid confusing errors down the line\n",
        "    assert (set(TARGETS_DF_COLUMNS) - set(targets_df.columns)) == set()\n",
        "    assert (set(PREDS_DF_COLUMNS) - set(preds_df.columns)) == set()\n",
        "\n",
        "    pred2error = dict()  # {pred_id: ErrorType}\n",
        "    target2pred = (\n",
        "        dict()\n",
        "    )  # {target_id: pred_id}, require iou > iou_foreground & max score\n",
        "    pred2target = dict()  # {pred_id: target_id}, require iou >= iou_background\n",
        "    missed_targets = set()  # {target_id}\n",
        "\n",
        "    # Higher scoring preds take precedence when multiple fulfill criteria\"\n",
        "    preds_df = preds_df.sort_values(by=\"score\", ascending=False)\n",
        "\n",
        "    for image_id, im_preds_df in preds_df.groupby(\"image_id\"):\n",
        "        # Need to reset index to access dfs with same idx we access\n",
        "        #   IoU matrix down the line\n",
        "        im_targets_df = targets_df.query(\"image_id == @image_id\").reset_index(\n",
        "            drop=True\n",
        "        )\n",
        "        im_preds_df = im_preds_df.reset_index(drop=True)\n",
        "\n",
        "        if im_targets_df.empty:\n",
        "            pred2error = {**pred2error, **_process_empty_image(im_preds_df)}\n",
        "        else:\n",
        "            iou_matrix, iou_label_match_matrix = _compute_iou_matrices(\n",
        "                im_targets_df, im_preds_df\n",
        "            )\n",
        "\n",
        "            # Iterate over all predictions. Higher scores first\n",
        "            for pred_idx in range(len(im_preds_df)):\n",
        "                match_found = _match_pred_to_target_with_same_label(\n",
        "                    pred_idx,\n",
        "                    pred2error,\n",
        "                    pred2target,\n",
        "                    target2pred,\n",
        "                    iou_label_match_matrix,\n",
        "                    im_targets_df,\n",
        "                    im_preds_df,\n",
        "                    iou_background,\n",
        "                    iou_foreground,\n",
        "                )\n",
        "                if match_found:\n",
        "                    continue\n",
        "\n",
        "                _match_pred_wrong_label_or_background(\n",
        "                    pred_idx,\n",
        "                    pred2error,\n",
        "                    pred2target,\n",
        "                    iou_matrix,\n",
        "                    im_targets_df,\n",
        "                    im_preds_df,\n",
        "                    iou_background,\n",
        "                    iou_foreground,\n",
        "                )\n",
        "\n",
        "    missed_targets = _find_missed_targets(targets_df, pred2target)\n",
        "    errors_df = _format_errors_as_dataframe(\n",
        "        pred2error, pred2target, missed_targets\n",
        "    )\n",
        "    return errors_df[list(ERRORS_DF_COLUMNS)]\n",
        "\n",
        "\n",
        "def _process_empty_image(im_preds_df: pd.DataFrame) -> Dict[int, str]:\n",
        "    \"\"\"In an image without targets, all predictions represent a background error\"\"\"\n",
        "    return {\n",
        "        pred_id: ErrorType.BKG for pred_id in im_preds_df[\"pred_id\"].unique()\n",
        "    }\n",
        "\n",
        "\n",
        "def _compute_iou_matrices(\n",
        "    im_targets_df: pd.DataFrame, im_preds_df: pd.DataFrame\n",
        ") -> Tuple[np.array, np.array]:\n",
        "    \"\"\"Compute IoU matrix between all targets and preds in the image\n",
        "    :param im_targets_df: DataFrame with targets for the image being processed.\n",
        "    :param im_preds_df: DataFrame with preds for the image being processed.\n",
        "    :return:\n",
        "        iou_matrix: Matrix of size (n_targets, n_preds) with IoU between all\n",
        "            targets & preds\n",
        "        iou_label_match_matrix: Same as `iou_matrix` but 0 for all target-pred\n",
        "            pair with different labels (i.e. IoU kept only if labels match).\n",
        "    \"\"\"\n",
        "    # row indexes point to targets, column indexes to predictions\n",
        "    iou_matrix = iou_matrix = torchvision.ops.box_iou(\n",
        "        torch.from_numpy(\n",
        "            im_targets_df[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n",
        "        ),\n",
        "        torch.from_numpy(im_preds_df[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values),\n",
        "    ).numpy()\n",
        "\n",
        "    # boolean matrix with True iff target and pred have the same label\n",
        "    label_match_matrix = (\n",
        "        im_targets_df[\"label_id\"].values[:, None]\n",
        "        == im_preds_df[\"label_id\"].values[None, :]\n",
        "    )\n",
        "    # IoU matrix with 0 in all target-pred pairs that have different label\n",
        "    iou_label_match_matrix = iou_matrix * label_match_matrix\n",
        "    return iou_matrix, iou_label_match_matrix\n",
        "\n",
        "\n",
        "def _match_pred_to_target_with_same_label(\n",
        "    pred_idx: int,\n",
        "    pred2error: Dict[int, str],\n",
        "    pred2target: Dict[int, int],\n",
        "    target2pred: Dict[int, int],\n",
        "    iou_label_match_matrix: np.array,\n",
        "    im_targets_df: pd.DataFrame,\n",
        "    im_preds_df: pd.DataFrame,\n",
        "    iou_background: float,\n",
        "    iou_foreground: float,\n",
        ") -> bool:\n",
        "    \"\"\"Try to match `pred_idx` to a target with the same label and identify error (if any)\n",
        "    If there is a match `pred2error`, `pred2target` and (maybe) `target2pred`\n",
        "    are modified in place.\n",
        "    Possible error types found in this function:\n",
        "        ErrorType.OK, ErrorType.DUP, ErrorType.LOC\n",
        "    :param pred_idx: Index of prediction based on score (index 0 is maximum score for image).\n",
        "    :param pred2error: Dict mapping pred_id to error type.\n",
        "    :param pred2target: Dict mapping pred_id to target_id (if match found with iou above background)\n",
        "    :param target2pred: Dict mapping target_id to pred_id to pred considered correct (if any).\n",
        "    :param iou_label_match_matrix: Matrix with size [n_targets, n_preds] with IoU between all preds\n",
        "        and targets that share label (i.e. IoU = 0 if there is a label missmatch).\n",
        "    :param im_targets_df: DataFrame with targets for the image being processed.\n",
        "    :param im_preds_df: DataFrame with preds for the image being processed.\n",
        "    :param iou_background: Minimum IoU to consider a pred not background for target.\n",
        "    :param iou_foreground: Minimum IoU to consider a pred foreground for a target.\n",
        "    :return matched: Whether or not there was a match and we could identify the pred error.\n",
        "    \"\"\"\n",
        "    # Find highest overlapping target for pred processed\n",
        "    target_idx = np.argmax(iou_label_match_matrix[:, pred_idx])\n",
        "    iou = np.max(iou_label_match_matrix[:, pred_idx])\n",
        "    target_id = im_targets_df.at[target_idx, \"target_id\"]\n",
        "    pred_id = im_preds_df.at[pred_idx, \"pred_id\"]\n",
        "\n",
        "    matched = False\n",
        "    if iou >= iou_foreground:\n",
        "        pred2target[pred_id] = target_id\n",
        "        # Check if another prediction is already the match for target to\n",
        "        #   identify duplicates\n",
        "        if target2pred.get(target_id) is None:\n",
        "            target2pred[target_id] = pred_id\n",
        "            pred2error[pred_id] = ErrorType.OK\n",
        "        else:\n",
        "            pred2error[pred_id] = ErrorType.DUP\n",
        "        matched = True\n",
        "\n",
        "    elif iou_background <= iou < iou_foreground:\n",
        "        pred2target[pred_id] = target_id\n",
        "        pred2error[pred_id] = ErrorType.LOC\n",
        "        matched = True\n",
        "    return matched\n",
        "\n",
        "\n",
        "def _match_pred_wrong_label_or_background(\n",
        "    pred_idx: int,\n",
        "    pred2error: Dict[int, str],\n",
        "    pred2target: Dict[int, int],\n",
        "    iou_matrix: np.array,\n",
        "    im_targets_df: pd.DataFrame,\n",
        "    im_preds_df: pd.DataFrame,\n",
        "    iou_background: float,\n",
        "    iou_foreground: float,\n",
        ") -> None:\n",
        "    \"\"\"Try to match `pred_idx` to a target (with different label) and identify error\n",
        "    If there is a match `pred2error` and  (maybe) `pred2target` are modified in place.\n",
        "    Possible error types found in this function:\n",
        "        ErrorType.BKG, ErrorType.CLS, ErrorType.CLS_LOC\n",
        "    :param pred_idx: Index of prediction based on score (index 0 is maximum score for image).\n",
        "    :param pred2error: Dict mapping pred_id to error type.\n",
        "    :param pred2target: Dict mapping pred_id to target_id (if match found with iou above background)\n",
        "    :param target2pred: Dict mapping target_id to pred_id to pred considered correct (if any).\n",
        "    :param iou: Matrix with size [n_targets, n_preds] with IoU between all preds and targets.\n",
        "    :param im_targets_df: DataFrame with targets for the image being processed.\n",
        "    :param im_preds_df: DataFrame with preds for the image being processed.\n",
        "    :param iou_background: Minimum IoU to consider a pred not background for target.\n",
        "    :param iou_foreground: Minimum IoU to consider a pred foreground for a target.\n",
        "    \"\"\"\n",
        "    # Find highest overlapping target for pred processed\n",
        "    target_idx = np.argmax(iou_matrix[:, pred_idx])\n",
        "    iou = np.max(iou_matrix[:, pred_idx])\n",
        "    target_id = im_targets_df.at[target_idx, \"target_id\"]\n",
        "    pred_id = im_preds_df.at[pred_idx, \"pred_id\"]\n",
        "\n",
        "    if iou < iou_background:\n",
        "        pred2error[pred_id] = ErrorType.BKG\n",
        "\n",
        "    # preds with correct label do not get here. Thus, no need to check if label\n",
        "    #   is wrong\n",
        "    elif iou >= iou_foreground:\n",
        "        pred2target[pred_id] = target_id\n",
        "        pred2error[pred_id] = ErrorType.CLS\n",
        "    else:\n",
        "        # No match to target, as we cannot be sure model was remotely close to\n",
        "        #   getting it right\n",
        "        pred2error[pred_id] = ErrorType.CLS_LOC\n",
        "\n",
        "\n",
        "def _find_missed_targets(\n",
        "    im_targets_df: pd.DataFrame, pred2target: Dict[int, int]\n",
        ") -> Set[int]:\n",
        "    \"\"\"Find targets in the processed image that were not matched by any prediction\n",
        "    :param im_targets_df: DataFrame with targets for the image being processed.\n",
        "    :param pred2target: Dict mapping pred_id to target_id (if match found with\n",
        "        iou above background)\n",
        "    :return missed_targets: Set of all the target ids that were missed\n",
        "    \"\"\"\n",
        "    matched_targets = [t for t in pred2target.values() if t is not None]\n",
        "    missed_targets = set(im_targets_df[\"target_id\"]) - set(matched_targets)\n",
        "    return missed_targets\n",
        "\n",
        "\n",
        "def _format_errors_as_dataframe(\n",
        "    pred2error: Dict[int, str],\n",
        "    pred2target: Dict[int, int],\n",
        "    missed_targets: Set[int],\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"Use the variables used to classify errors to format them in a ready to use DataFrame\n",
        "    :param pred2error: Dict mapping pred_id to error type.\n",
        "    :param pred2target: Dict mapping pred_id to target_id (if match found with\n",
        "        iou above background)\n",
        "    :param missed_targets: Set of all the target ids that were missed\n",
        "    :return: DataFrame with columns ERRORS_DF_COLUMNS\n",
        "    \"\"\"\n",
        "    errors_df = pd.DataFrame.from_records(\n",
        "        [\n",
        "            {\"pred_id\": pred_id, \"error_type\": error}\n",
        "            for pred_id, error in pred2error.items()\n",
        "        ]\n",
        "    )\n",
        "    errors_df[\"target_id\"] = None\n",
        "    errors_df.set_index(\"pred_id\", inplace=True)\n",
        "    for pred_id, target_id in pred2target.items():\n",
        "        errors_df.at[pred_id, \"target_id\"] = target_id\n",
        "\n",
        "    missed_df = pd.DataFrame(\n",
        "        {\n",
        "            \"pred_id\": None,\n",
        "            \"error_type\": ErrorType.MISS,\n",
        "            \"target_id\": list(missed_targets),\n",
        "        }\n",
        "    )\n",
        "    errors_df = pd.concat(\n",
        "        [errors_df.reset_index(), missed_df], ignore_index=True\n",
        "    ).astype(\n",
        "        {\"pred_id\": float, \"target_id\": float, \"error_type\": pd.StringDtype()}\n",
        "    )\n",
        "    return errors_df"
      ],
      "metadata": {
        "id": "MCse3qzf8Qps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors_df = classify_predictions_errors(targets_df, preds_df)"
      ],
      "metadata": {
        "id": "B9tY04cu8dSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors_df[\"error_type\"].value_counts()"
      ],
      "metadata": {
        "id": "K0w8HUDe8ez9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f7d1cea-ad41-41d9-dc58-372fa5c5cc2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "background        304058\n",
              "localization       98112\n",
              "cls & loc          72522\n",
              "classification     45790\n",
              "correct            33536\n",
              "duplicate          25407\n",
              "missed              1193\n",
              "Name: error_type, dtype: Int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}
